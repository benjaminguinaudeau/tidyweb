---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->
# tidyweb <img src="man/figures/tidyweb_logo.png" width="160px" align="right" />

+ Todo
  * include htm-package send by fabio


```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)

```

```{r, echo = FALSE, results='asis', eval = T}

library(badger)

git_repo <- "benjaminguinaudeau/tidyweb"

cat(
  badge_lifecycle(),
	badge_code_size(git_repo),
	badge_last_commit(git_repo)
)
```

>Use tidy data principles to interact with HTML files!

This package is meant to ease web scraping with Selenium by "tidying" the html structure. To do so, it iterates recursively on web elements until a given depth and returns a tibble, with the children elements nested in list-columns. That way, tidy principles can be used to identify specific elements and eventually interact with them. 

## Install

```{r, message=FALSE}
# remotes::install_github("benjaminguinaudeau/tidyweb")
library(tidyweb)
library(dplyr)
```

## How to use with Rvest?

```{r}
page <- xml2::read_html("https://www.nytimes.com/")

art <- page %>%
  rvest::html_nodes("article")


parsed_art <- art %>% tidy_element(depth = 10) 

parsed_art %>% glimpse
parsed_art %>% filter(!is.na(href)) %>% glimpse
parsed_art %>% 
  separate_rows(class, sep = "\\s+") %>%
  count(class, sort = T) %>%
  glimpse

parsed_art %>% 
  mutate(depth = str_count(.id, "_") + 1) %>%
  group_by(depth) %>%
  ggplot(aes(x = depth)) + geom_histogram()
  

```

